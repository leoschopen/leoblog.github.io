{"meta":{"title":"Leo's Blog","subtitle":"","description":"","author":"Leo Schopen","url":"https://leoschopen.github.io"},"pages":[{"title":"about","date":"2023-05-28T08:56:30.000Z","updated":"2023-05-28T08:56:30.656Z","comments":false,"path":"about/index.html","permalink":"https://leoschopen.github.io/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-04-03T03:52:36.000Z","updated":"2020-07-03T07:30:19.009Z","comments":false,"path":"categories/index.html","permalink":"https://leoschopen.github.io/categories/index.html","excerpt":"","text":"Catagories"},{"title":"tags","date":"2020-04-03T03:51:52.000Z","updated":"2020-07-03T07:30:29.939Z","comments":false,"path":"tags/index.html","permalink":"https://leoschopen.github.io/tags/index.html","excerpt":"","text":"Tags"}],"posts":[{"title":"MapReduce论文阅读","slug":"MapReduce论文阅读","date":"2023-11-06T12:43:00.000Z","updated":"2023-11-06T12:48:10.709Z","comments":true,"path":"2023/11/06/MapReduce论文阅读/","link":"","permalink":"https://leoschopen.github.io/2023/11/06/MapReduce%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","excerpt":"","text":"MapReduce论文阅读 相关背景 Google需要在TB级别的数据上进行大量的计算，比如对所有的网页创建索引并进行查找排序，词频排序，多台机器上文件进行grep，如何将这个操作跑在几千台机子上？ 要么就是针对这个具体的场景设置并行计算，分布式软件，但是google想要一个框架，使得工程师只要表述想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，也可以完成大规模的分布式运算。这些问题都被封装在了一个库里面：利用一个输入 key/value pair 集合来产生一个输出的 key/value pair 集合。这就是mapReduce框架出现的背景。 这些需要解决的问题往往是通用的 多机并行协同，网络通信，错误处理，提高执行效率等 google三件客 gfs bigtable 《MapReduce: Simplified Data Processing on Large Clusters 》 Map本质就是拆解Reduce就是拼接 场景 mapreduce的6大过程在不同场景下的体现 词频排序 重建倒排索引 输入是文件与内容，输出就是单词以及相应的文档号 map就是将每个内容拆分出单词与文档号，后面reduce进行汇合 分布式grep等等… MapReduce 介绍 多个机器，用以太网交换机相连 使用内部的分布式的文件系统来管理磁盘上的数据，文件系统通过复制在不可靠的硬件上保证数据的可靠性和有效性 用户提交job，每个job都包含一系列的任务task，调度系统将这些任务调度到集群中多台可用的机器上 采用分而治之的思想，将大的计算任务分为小的计算任务，将文件分片导不同的datanode上，每个node单独做一定的操作，最后reduce 流程 将输入的数据使用map函数返回一个kv对作为中间数据集合，然后将相同k的数据集合在一起输入到reduce函数中处理执行，reduce合并这些数据，最后返回处理后的结果 12map(k1,v1) -&gt;list(k2,v2)reduce(k2,list(v2)) -&gt;list(v2) 首先有一个用户进程，用来定义需要运行什么，有哪些事 会分析数据有多少，拆分为M片，这里需要一个数据的格式，将数据变成KV的形式 需要一个master worker，跟其他的等级一样，只不过干一些特殊的事情，作为用户的代理来协调整个过程，比如协调各个worker拿不同的数据 每个map worker读取相应的输入数据，解析出kv对，然后交给map函数生成中间kv对，在缓存中存储相应的数据 缓存中的kv对分成R个区域，之后周期性地写入本地磁盘上，缓存的kv对在本地磁盘上的位置再回传给master，master将这些存储位置传给reduce worker reduce worker做数据的整合，使用rpc读取这些数据，对key进行排序后使得相同的k的值聚合在一起，不同的key值会映射到相同的reduce任务上，因为中间数据太大无法再内存中完成排序，那么就要外部排序 reduce worker遍历排序后的中间数据，将key以及对应的value list送给reduce函数，reduce输出被追加到所属分区的输出文件 当所有的map和reduce认为都完成后，master唤醒用户程序 优点 这个过程很利于并行化，map可以在多个机器上，这些机器之间不需要协调，没有依赖，没有同步问题，所有的依赖性和协调过程被隐藏在map和reduce的数据分发和收集之间，但是map和reduce之间是有依赖是串行的 那么这个模型就能够应对局部性失败的容错性，系统不会因为小的局部机器的失败造成整个系统的崩溃和不可用，这也是分布式容错性的本质-在不可靠的硬件上构建可靠的软件 容错 worker 故障 master 与 worker 之间同步心跳，对于失效的 worker，根据其类型来做进一步处理： Map worker 故障：由于 Map 任务将数据临时存储在本地，所以需要重新执行。 Reduce worker 故障：由于 Reduce 任务将数据存储在全局文件系统中 ，所以不需要重新执行。 master 故障 MapReduce 任务重新执行 故障语义保证 当map和reduce函数的操作是确定性函数（相同的输入产生相同输出），mapreduce的分布式结果与其一致 存储位置优化 核心思想：本地读文件以减少流量消耗 MapReduce 的 master 在调度 Map 任务时会考虑输入文件的位置信息，尽量将一个 Map 任务调度在包含相关输入数据拷贝的机器上执行；如果上述努力失败了，master 将尝试在保存有输入数据拷贝的机器附近的机器上执行 Map 任务（例如，分配到一个和包含输入数据的机器在一个交换机里的 worker 机器上执行）。 任务粒度 理想情况下，M 和 R 应当比集群中 worker 的机器数量要多得多。在每台 worker 机器都执行大量的不同任务能够提高集群的动态的负载均衡能力，并且能够加快故障恢复的速度：失效机器上执行的大量 Map 任务都可以分布到所有其他的 worker 机器上去执行。 实际使用时建议用户选择合适的 M 值，以使得每一个独立任务都是处理大约 16M 到 64M 的输入数据（这样，上面描写的输入数据本地存储优化策略才最有效），另外，也建议把 R 值设置使用的 worker 机器数量的小倍数。比如：M=200000，R=5000，使用 2000 台 worker 机器 backup进程 影响一个 MapReduce 的总执行时间最通常的因素是“落伍者”：在运算过程中，如果有一台机器花了很长的时间才完成最后几个 Map 或 Reduce 任务，导致 MapReduce 操作总的执行时间超过预期。 为了解决落伍者的问题，当一个 MapReduce 操作接近完成的时候，master 调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行进程、还是备用（backup）任务进程完成了任务，MapReduce 都把这个任务标记成为已经完成。此个机制通常只会占用比正常操作多几个百分点的计算资源。但能减少近 50% 的任务完成总时间。 Details 分区函数 缺省的分区函数是使用 hash 方法（比如，hash(key) mod R) ，将同一个key保存在同一个输出文件中。 Contribution 使用简单的接口实现了自动化的并行化和大规模的分布式计算，通过使用 MapReduce 模型接口实现了在大量普通 PC 机上的高性能计算。 证明MapReduce在分布式计算上的可行性，拉开分布式计算序幕，影响后续的Spark，Flink等。 不足 由于成本等原因，没有利用内存更高效处理数据 没有将资料调度和计算调度分离。使得MapReduce 系统看起来较为冗杂。在开源的 Hadoop 生态中，MapReduce 现只关注于计算，具体的资源调度由 Yarn 管理。 总结 网络带宽是稀有资源。大量的系统优化是针对减少网络传输量为目的的：本地优化策略使大量的数据从本地磁盘读取，中间文件写入本地磁盘、并且只写一份中间文件也节约了网络带宽。 多次执行相同的任务可以减少硬件配置不平衡带来的负面影响，同时解决了由于机器失效导致的数据丢失问题。 相关系统 分布式存储系统：GFS/Colossus/HDFS 批处理框架：Spark 流处理框架：Flink 高可用机制：Chubby/ZooKeeper 相关资料 6.824 视频 论文 中文翻译","categories":[{"name":"分布式","slug":"分布式","permalink":"https://leoschopen.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"论文阅读","slug":"分布式/论文阅读","permalink":"https://leoschopen.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}],"tags":[{"name":"分布式系统","slug":"分布式系统","permalink":"https://leoschopen.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://leoschopen.github.io/tags/MapReduce/"}],"keywords":[{"name":"分布式","slug":"分布式","permalink":"https://leoschopen.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"论文阅读","slug":"分布式/论文阅读","permalink":"https://leoschopen.github.io/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"}]},{"title":"RAII原理介绍","slug":"RAII原理介绍","date":"2023-06-14T07:49:00.000Z","updated":"2023-06-14T07:50:22.070Z","comments":true,"path":"2023/06/14/RAII原理介绍/","link":"","permalink":"https://leoschopen.github.io/2023/06/14/RAII%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"RAII原理介绍 什么是RAII RAII（Resource Acquisition Is Initialization）是由c++之父Bjarne Stroustrup提出的，中文翻译为资源获取即初始化，他说：使用局部对象来管理资源的技术称为资源获取即初始化；这里的资源主要是指操作系统中有限的东西如内存、网络套接字等等，局部对象是指存储在栈的对象，它的生命周期是由操作系统来管理的，无需人工介入； 总结来说就是一种对资源申请、释放这种成对的操作的封装，使用局部对象自动销毁的特性来让控制资源的生命周期。 给一个简单的例子来看下局部对象的自动销毁的特性： 12345678910111213141516171819202122232425262728293031#include &lt;iostream&gt;using namespace std;class person &#123; public: person(const std::string name = &quot;&quot;, int age = 0) : name_(name), age_(age) &#123; std::cout &lt;&lt; &quot;Init a person!&quot; &lt;&lt; std::endl; &#125; ~person() &#123; std::cout &lt;&lt; &quot;Destory a person!&quot; &lt;&lt; std::endl; &#125; const std::string&amp; getname() const &#123; return this-&gt;name_; &#125; int getage() const &#123; return this-&gt;age_; &#125; private: const std::string name_; int age_; &#125;;int main() &#123; person p; return 0;&#125;编译并运行：g++ person.cpp -o person./person 运行结果：Init a person!Destory a person! 当整个main函数执行完成后，自动调用析构函数来销毁对象，整个过程无需人工介入，由操作系统自动完成；于是，很自然联想到，当我们在使用资源的时候，在构造函数中进行初始化，在析构函数中进行销毁。整个RAII过程我总结四个步骤： a.设计一个类封装资源 b.在构造函数中初始化 c.在析构函数中执行销毁操作 d.使用时声明一个该对象的类 项目中的使用例子：数据库连接池的实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class SqlConnectionPool &#123;public: SqlConnectionPool(); ~SqlConnectionPool(); MYSQL *GetConnection(); //获取数据库连接 bool ReleaseConnection(MYSQL *conn); //释放连接 void DestroyPool(); //销毁所有连接 //单例模式 static SqlConnectionPool *GetInstance(); void init(string host, int port, string user_name, string password, string database_name, unsigned int max_connection);private: unsigned int max_connection_; //最大连接数 unsigned int cur_connection_; //当前已使用的连接数 unsigned int free_connection_; //当前空闲的连接数private: Locker locker_; std::list&lt;MYSQL *&gt; connection_list_; //连接池 Semaphore semaphore_; std::string host_; //主机地址 unsigned int port_; //数据库端口号 std::string user_name_; //登陆数据库用户名 std::string password_; //登陆数据库密码 std::string database_name_; //使用数据库名&#125;;class ConnectionRAII &#123;public: // 构造函数中初始化数据库连接与数据库连接池 ConnectionRAII(MYSQL **SQL, SqlConnectionPool *connPool); // 析构函数销毁数据库连接 ~ConnectionRAII();private: MYSQL *connection_RAII_; SqlConnectionPool *connection_pool_RAII_;&#125;;// 使用时声明一个该对象的类，MYSQL *mysql = nullptr;ConnectionRAII mysql_conn(&amp;mysql, connPool); 这样mysql_conn对象在离开作用域的时候 参考 https://zhuanlan.zhihu.com/p/34660259","categories":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/tags/c/"}],"keywords":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}]},{"title":"C++ 对象移动、右值引用与完美转发","slug":"对象移动、右值引用与完美转发","date":"2023-06-14T01:02:00.000Z","updated":"2023-09-01T12:43:07.239Z","comments":true,"path":"2023/06/14/对象移动、右值引用与完美转发/","link":"","permalink":"https://leoschopen.github.io/2023/06/14/%E5%AF%B9%E8%B1%A1%E7%A7%BB%E5%8A%A8%E3%80%81%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E4%B8%8E%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91/","excerpt":"","text":"对象移动、右值引用与完美转发 移动 新标准的一个最主要的特性是可以移动而非拷贝对象的能力。 旧标准中很多情况下的拷贝操作实际上是消耗很大的，比如string等 右值引用&amp;&amp; 右值引用(rvalue references)是C++11里面最重要的新特性了。移动语义和完美转发都建立在它的基础之上。 为了支持移动操作，新标准引入了 一种新的引用类型一右值引用。 右值引用有一个重要的性质一只能绑定到一个将要销毁的对象。 左值是持久的对象，右值是短暂的，要不是一个临时对象，要不是一个字面常量。 但是不能将一个左值绑定到一个右值上，但是可以使用move 1int &amp;&amp;r2 = r1; 移动构造函数 移动构造函数不应该抛出任何异常，不抛出异常的移动构造函数和移动赋值运算符必须标记为noexcept。 在移动构造函数内部，我们接管给定目标的内存后，将其中的指针都置空 以下是一个简单的示例，说明了移动构造函数如何销毁原始对象： 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;utility&gt;class Example &#123;public: Example() &#123; std::cout &lt;&lt; &quot;Default constructor called&quot; &lt;&lt; std::endl; data_ = new int(0); &#125; // 移动构造函数 Example(Example&amp;&amp; other) noexcept &#123; std::cout &lt;&lt; &quot;Move constructor called&quot; &lt;&lt; std::endl; data_ = other.data_; other.data_ = nullptr; &#125; ~Example() &#123; std::cout &lt;&lt; &quot;Destructor called&quot; &lt;&lt; std::endl; delete data_; &#125;private: int* data_;&#125;;int main() &#123; Example obj1; // 创建对象obj1，输出 Default constructor called Example obj2(std::move(obj1)); // 使用移动构造函数创建对象obj2，输出 Move constructor called return 0; // 输出 Destructor called 两遍&#125; 在上面的示例中，我们首先创建了一个名为obj1的对象，它使用默认构造函数分配了一个整数的动态内存。然后，我们使用移动构造函数将obj1的所有权转移到了obj2，obj1的资源指针被设置为nullptr。 但是此时这个obj1还是一个有效的源对象，只不过其指针为空，其值没有任何要求。但是我们要保证在转移后原对象必须可析构。在移动操作之后，移后源对象必须保持有效的、可析构的状态，但是用户不能对其值进行任何假设。 当程序结束时，obj2的析构函数首先被调用，释放了它拥有的资源。接着，obj1的析构函数被调用，它检测到资源指针为nullptr. 合成的移动构造函数 在声明了拷贝构造，拷贝赋值或者析构，编译器不会为他合成移动构造函数和移动赋值运算符，这个时候通过正常的函数匹配，类会使用对应的拷贝操作来代替移动操作。 只有没有定义任何拷贝控制成员（五法则的那几个）并且非static所有数据成员都能够移动构造或移动赋值时，才会为他合成移动构造和移动赋值 此外合成的移动构造不像其他拷贝构造等不符合要求的情况下会造成隐式删除，因为这种情况下编译器就不会生成合成的，即使显式声明为default，也会被定义为删除。 下面这种情况就是，因为这个类有成员无法被移动。 如果类定义了一个移动构造函数和I或一个移动赋值运算符， 则该类的合成拷贝构造函数和拷贝赋值运算符会被定义为删除的。 完美转发 完美转发 = 引用折叠 + 万能引用 + std::forward 完美转发它的作用是保持原来的值属性不变。如果原来的值是左值，经std::forward处理后该值还是左值；如果原来的值是右值，经std::forward处理后它还是右值。 std::forward不是独自运作的，在我的理解里，完美转发 = std::forward + 万能引用 + 引用折叠。三者合一才能实现完美转发的效果。 std::forward的正确运作的前提，是引用折叠机制，为T &amp;&amp;类型的万能引用中的模板参数T赋了一个恰到好处的值。我们用T去指明std::forward的模板参数，从而使得std::forward返回的是正确的类型。 为什么要使用完美转发？ 完美转发基于万能引用，引用折叠以及std::forward模板函数。据我所知，STL出现std::forward，一定出现万能引用。其实这也很好理解**，完美转发机制，是为了将左值和右值统一处理，节约代码量**，而只有万能引用会出现同时接受左值和右值的情况，所以完美转发只存在于万能引用中。 12345678910111213141516171819202122232425template&lt;typename T&gt;void print(T &amp; t)&#123; std::cout &lt;&lt; &quot;Lvalue ref&quot; &lt;&lt; std::endl;&#125;template&lt;typename T&gt;void print(T &amp;&amp; t)&#123; std::cout &lt;&lt; &quot;Rvalue ref&quot; &lt;&lt; std::endl;&#125;template&lt;typename T&gt;void testForward(T &amp;&amp; v)&#123; print(v);//v此时已经是个左值了,永远调用左值版本的print print(std::forward&lt;T&gt;(v)); //本文的重点 print(std::move(v)); //永远调用右值版本的print std::cout &lt;&lt; &quot;======================&quot; &lt;&lt; std::endl;&#125;int main(int argc, char * argv[])&#123; int x = 1; testForward(x); //实参为左值 testForward(std::move(x)); //实参为右值&#125; 12345678Lvalue refLvalue refRvalue ref======================Lvalue refRvalue refRvalue ref====================== 可以看到，在testForward中，虽然参数v是右值类型的，但此时v在内存中已经有了位置，所以v其实是个左值！ 也就是说虽然你的参数想要是个右值，但实际上却是一个左值：右值的概念其实很微妙，一旦某个右值，有了名字，也就在内存中有了位置，它就变成了1个左值。本质问题在于，左值右值在函数调用时，都转化成了左值，使得函数转调用时无法判断左值和右值。 万能引用 1234template&lt;typename T&gt;void func(T&amp; param) &#123; cout &lt;&lt; param &lt;&lt; endl;&#125; 上面的模板函数只能接受左值或者左值引用（左值一般是有名字的变量，可以取到地址的）但是，有没有办法只写一个模板函数即可以接收左值又可以接收右值呢？ 1234template&lt;typename T&gt;void func(T&amp;&amp; param) &#123; cout &lt;&lt; param &lt;&lt; endl;&#125; C++ 11中有万能引用（Universal Reference）的概念：使用T&amp;&amp;类型的形参既能绑定右值，又能绑定左值。 但是注意了：只有发生类型推导的时候，T&amp;&amp;才表示万能引用；否则，表示右值引用。 引用折叠 一个模板函数，根据定义的形参和传入的实参的类型，我们可以有下面四中组合： 左值-左值 T&amp; &amp; # 函数定义的形参类型是左值引用，传入的实参是左值引用 左值-右值 T&amp; &amp;&amp; # 函数定义的形参类型是左值引用，传入的实参是右值引用 右值-左值 T&amp;&amp; &amp; # 函数定义的形参类型是右值引用，传入的实参是左值引用 右值-右值 T&amp;&amp; &amp;&amp; # 函数定义的形参类型是右值引用，传入的实参是右值引用 但是C++中不允许对引用再进行引用，对于上述情况的处理有如下的规则： 所有的折叠引用最终都代表一个引用，要么是左值引用，要么是右值引用。规则是：如果任一引用为左值引用，则结果为左值引用。否则（即两个都是右值引用），结果为右值引用。 即就是前面三种情况代表的都是左值引用，而第四种代表的右值引用。 参考 https://zhuanlan.zhihu.com/p/369203981 https://zhuanlan.zhihu.com/p/260508149 https://zhuanlan.zhihu.com/p/99524127","categories":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/tags/c/"}],"keywords":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}]},{"title":"C++ 内存泄漏问题与智能指针","slug":"内存泄漏问题与智能指针","date":"2023-06-12T12:25:00.000Z","updated":"2023-09-01T12:47:34.695Z","comments":true,"path":"2023/06/12/内存泄漏问题与智能指针/","link":"","permalink":"https://leoschopen.github.io/2023/06/12/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E4%B8%8E%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/","excerpt":"","text":"1.1 为什么需要内存管理机制？ 有些内存资源已经被释放，但指向它的指针并没有改变指向（成为了野指针），并且后续还在使用； 有些内存资源已经被释放，后期又试图再释放一次（重复释放同一块内存会导致程序运行崩溃）； 没有及时释放不再使用的内存资源，造成内存泄漏，程序占用的内存资源越来越多。 1.2 解决方案 C++11 新标准在废弃 C++98/03 标准中的auto_ptr，增添了 unique_ptr、shared_ptr 以及 weak_ptr 这 3 个智能指针来实现堆内存的自动回收。 底层是采用引用计数的方式实现的。简单的理解，智能指针在申请堆内存空间的同时，会为其配备一个整形值（初始值为 1），每当有新对象使用此堆内存时，该整形值 +1；反之，每当使用此堆内存的对象被释放时，该整形值减 1。当堆空间对应的整形值为 0 时，即表明不再有对象使用它，该堆空间就会被释放掉。 智能指针，正如它的名字一样，似乎是个近乎完美的聪明角色，程序员不用再纠结于new出来的内存在哪释放比较合适这种问题。比如当一个资源被多个模块共享时，程序员需要在所有模块的生命周期都结束时，由最后一个不使用该指针的模块触发指针的释放行为，而模块的生命周期可能根本在写代码时就确定不了。 1.3 C++11 shared_ptr 智能指针 当所有指针都释放（或是不再指向对象）的时候，自动释放对象 创建，智能指针是以类模板的方式实现的,创建的时候需要指定其相应的类型 12345std::shared_ptr&lt;int&gt; p1; std::shared_ptr&lt;int&gt; p2(nullptr);std::shared_ptr&lt;int&gt; p3(new int(10));std::shared_ptr&lt;int&gt; p4(p3);//或者 std::shared_ptr&lt;int&gt; p4 = p3;std::shared_ptr&lt;int&gt; p5(std::move(p4)); //或者 std::shared_ptr&lt;int&gt; p5 = std::move(p4); 1.3.1 动态数组的释放 shared_ptr 指针默认的释放规则是不支持释放数组的，只能自定义对应的释放规则 123456std::shared_ptr&lt;int&gt; p6(new int[10], std::default_delete&lt;int[]&gt;());void deleteInt(int*p) &#123; delete []p;&#125;std::shared_ptr&lt;int&gt; p7(new int[10], deleteInt);std::shared_ptr&lt;int&gt; p7(new int[10], [](int* p) &#123;delete[]p; &#125;); 1.3.2 优先使用std::make_unique和std::make_shared而不是直接使用new 创造shared_ptr的好工具 效率更高：只会分配一次内存，包括对象的内存以及智能指针控制块的内存 解决重复释放问题：解决 double free detected 问题，多个智能指针指向同一个手动创建的堆空间，彼此不知道对方的存在，会造成重复释放的问题 异常安全:见下面的例子，在运行时，函数被调用前函数的参数会被推算，但是参数的求值顺序是不一样的，如果先创建了widget，再执行了computePriority，而computePriority出现了异常会造成智能指针没有指向widget，从而造成内存泄漏，但是make_shared不会，是一体的操作 重复释放的例子: 123auto p1 = new Test; // 划分堆空间 std::shared_ptr&lt;Test&gt; sp(p1); // 创建智能指针std::shared_ptr&lt;Test&gt; sp2(p1); // 创建另一个智能指针 异常安全的例子 123processWidget(std::shared_ptr&lt;Widget&gt;(new Widget),computePriority())processWidget(std::make_shared&lt;Widget&gt;(),computePriority); 注意，为了正确使用 shared_ptr，我们应该遵循以下原则： 每个 shared_ptr 对象应该拥有自己的内存资源，不应该共享同一块内存。 使用 shared_ptr 初始化时，应该使用 new 运算符来分配内存，而不是使用一个已经存在的指针。 如果需要共享同一块内存，应该使用 weak_ptr 来进行共享。 1.3.3 make_shared缺点 1.3.3.1 构造函数是保护或者私有时，无法使用make_shared 由于make_shared附带了对象的创建，因此会调用对象的构造函数，如果该类没有共有构造函数，需要使用技巧 1234567891011121314#include &lt;memory&gt;class A&#123;public: static std::shared_ptr&lt;A&gt; create() &#123; struct make_shared_enabler : public A &#123;&#125;; return std::make_shared&lt;make_shared_enabler&gt;(); &#125;private: A() &#123;&#125; &#125;; 1.3.3.2 如果有weak_ptr，对象的内存可能无法及时回收 因为make_shared只申请一次内存，因此控制块和数据块在一起，只有但控制块中不再使用时，内存才会释放。但是如果还有weak_ptr指向该块对象所在的内存，存放管理对象的部分内存仍然不会被释放，因而导致在所有其他weak_ptr销毁前整块内存（尽管被管理对象已经析构了）将不会进入系统的内存池循环使用 1.4 weak_ptr ：shared_ptr的好帮手 weak_ptr是用来指向shared_ptr的，因此weak_ptr主要有两个用途： 用来记录对象是否存在了 用来解决shared_ptr环形依赖的问题 123456shared_ptr&lt;int&gt; sp(new int(10)); weak_ptr&lt;int&gt; wp(sp);if(wp.expired()) cout &lt;&lt; &quot;weak_ptr无效,资源已释放&quot;; else cout &lt;&lt; &quot;weak_ptr有效&quot;; 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;class A &#123;public: std::shared_ptr&lt;B&gt; bptr; ~A() &#123; cout &lt;&lt; &quot;A is deleted&quot; &lt;&lt; endl; &#125;&#125;;class B &#123;public: std::shared_ptr&lt;A&gt; aptr; ~B() &#123; cout &lt;&lt; &quot;B is deleted&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; &#123;//设定一个作用域 std::shared_ptr&lt;A&gt; ap(new A); std::shared_ptr&lt;B&gt; bp(new B); ap-&gt;bptr = bp; bp-&gt;aptr = ap; &#125; cout&lt;&lt; &quot;main leave&quot; &lt;&lt; endl; // 循环引用导致ap bp退出了作用域都没有析构 return 0;&#125; 以下是循环引用的过程： 创建 shared_ptr&lt;A&gt; ap，其引用计数为 1。 创建 shared_ptr&lt;B&gt; bp，其引用计数为 1。 将 bp 赋值给 ap-&gt;bptr，B 对象的引用计数变为 2。 将 ap 赋值给 bp-&gt;aptr，A 对象的引用计数变为 2。 此时，A 和 B 对象的引用计数都为 2。由于它们互相引用，它们的引用计数永远不会减少到 0。因此，在离开 main 函数的作用域时，析构函数不会被调用，导致内存泄漏。 1.4.1 注意事项 通过shared_ptr返回this指针：weak_ptr基本用法以及怎么解决循环引用_星河九天的博客-CSDN博客，正确的方法是 shared_from_this() r在使用前需要检查合法性，其指向的shared_ptr不能是已释放的，否则会返回一个空指针 2 参考 C++11 shared_ptr智能指针（超级详细） Item 21 优先使用std::make_unique和std::make_shared而不是直接使用new weak_ptr基本用法以及怎么解决循环引用_星河九天的博客-CSDN博客 C/C++编程：理解make_shared_OceanStar的学习笔记的博客-CSDN博客","categories":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}],"tags":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/tags/c/"}],"keywords":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}]},{"title":"C++ 不使用sizeof如何求变量的占用字节？","slug":"不使用sizeof如何求变量的占用字节？","date":"2023-06-07T12:38:00.000Z","updated":"2023-09-01T12:42:58.022Z","comments":true,"path":"2023/06/07/不使用sizeof如何求变量的占用字节？/","link":"","permalink":"https://leoschopen.github.io/2023/06/07/%E4%B8%8D%E4%BD%BF%E7%94%A8sizeof%E5%A6%82%E4%BD%95%E6%B1%82%E5%8F%98%E9%87%8F%E7%9A%84%E5%8D%A0%E7%94%A8%E5%AD%97%E8%8A%82%EF%BC%9F/","excerpt":"","text":"使用相邻两个变量的地址，求他们之间的差 1#define mySizeof(type) (&amp;type+1) - (&amp;type) 但是验证的结果会发现，结果是1，代表两个变量之间的变量数，其单位是数目而非字节 因此考虑将该内容转为char指针，因为char占用的空间是一个字节 123456789101112131415#include &lt;iostream&gt;using namespace std;#define mySizeof(type) (char*)(&amp;type+1) - (char*)(&amp;type)int main()&#123; int i=0; cout &lt;&lt; &amp;i &lt;&lt; endl; cout &lt;&lt; &amp;i+1 &lt;&lt; endl; cout &lt;&lt; (char*)(&amp;i) &lt;&lt; endl; cout &lt;&lt; (char*)(&amp;i+1) &lt;&lt; endl; cout &lt;&lt; mySizeof(i) &lt;&lt; endl; cout &lt;&lt; sizeof(i) &lt;&lt; endl; return 0;&#125; (char*)(&amp;i)将整型变量 i 的地址强制转换为 char* 类型的指针。这个操作并不会在内存中进行任何实际的操作，它只是将该地址的类型从 int* 转换为 char*。这个转换不会改变该地址所指向的内存位置，只是改变了该地址的解释方式，使得编译器可以将该地址解释为指向字符的指针。 当前机器使用小端序（即低地址存放低位字节），则将整型变量 i 的地址强制转换为 char* 指针并输出时，会将 i 的内存位置的低位字节（即第一个字节）的值作为字符输出，因为在小端序中，低位字节的地址是最小的。由于 i 的值为 0，它的内存位置的所有字节的值都为 0，因此(char*)(&amp;i)输出的字符是空字符（ASCII 码为 0）。 而(char*)(&amp;i+1)对应的内容将会是未定义的内容，其显示依赖与系统。","categories":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}],"tags":[],"keywords":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}]},{"title":"进程同步与互斥相关内容总结","slug":"条件变量的若干问题","date":"2023-05-24T14:59:00.000Z","updated":"2023-07-19T13:53:20.825Z","comments":true,"path":"2023/05/24/条件变量的若干问题/","link":"","permalink":"https://leoschopen.github.io/2023/05/24/%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98/","excerpt":"","text":"进程同步与互斥相关内容总结 为什么需要进程同步 多道程序并发执行如果不加以管理，其对资源的无序争夺会造成混乱（间断、失去封闭与不可再现） 操作系统中的进程同步解决方法有 机制 原理 适用问题 硬件同步机制 访问的资源忙碌的时候就要等待，不符合让权等待，也不能处理复杂的同步问题。 互斥 信号量 核心是计数器，控制资源的访问，特殊例子（资源数为1）-互斥量/锁 同步与互斥 管程 面向对象，各种同步互斥操作，还会使用到条件变量 同步互斥 条件变量 利用线程间共享的全局变量进行同步，不满足条件挂起，满足释放 同步 读写锁 类似互斥锁，读的时候可以读不可以写，写的时候不可以读写 同步 自旋锁 类似互斥锁，但是阻塞之后不会让出cpu，会忙等，使用场景的锁的持有时间较短，内核态使用较多 同步 信号量与条件变量之间的区别 信号量=条件变量+锁 信号量内部对value进行管理，条件变量外部对value进行判断 如果用信号量，当wait(s)的时候，默认了“我使用s，并且根据情况判断是否等待s，我会value–”。但如果用条件变量，就只有一个语义，就是“我等待s” 为什么有互斥锁，还需要条件变量？ 互斥锁和条件变量所解决的，是不同的问题，不同的场景。 互斥锁解决的是在 shared memory space 模型下，多个线程对同一个全局变量的访问的竞争问题。当一个线程想要访问临界区的时候会先加锁，其他线程将会等待，这些等待的线程是因为没有锁而被block。 但是如果遇到了如下的场景：一个线程要等待一个条件才能继续执行，而这个条件只能由另一个进程来满足，比如T1不断给一个全局变量 x +1， T2检测到x 大于100时，将x 置0，如果我们没有条件变量，则只通过互斥锁则可以有如下实现: 123456789101112131415161718192021222324252627/* * Assume we have global variables: * int iCount == 0; * pthread_cond_t cond = PTHREAD_COND_INITIALIZER; *///thread 1:while(true)&#123; pthread_mutex_lock(&amp;mutex); iCount++; pthread_mutex_unlock(&amp;mutex);&#125;//thread 2:while(true)&#123; pthread_mutex_lock(&amp;mutex); if(iCount &gt;= 100) &#123; iCount = 0; &#125; pthread_mutex_unlock(&amp;mutex);&#125; thread 2需要不断地&lt;加锁，判断，解锁&gt;，开销很大，如果让 thread2先被 block，等条件满足的时候再唤醒 thread2就会降低开销，这就是条件变量 123456789101112131415161718192021222324252627//thread1 :while(true)&#123; pthread_mutex_lock(&amp;mutex); iCount++; pthread_mutex_unlock(&amp;mutex); pthread_mutex_lock(&amp;mutex); if(iCount &gt;= 100) &#123; pthread_cond_signal(&amp;cond); &#125; pthread_mutex_unlock(&amp;mutex);&#125;//thread2:while(1)&#123; pthread_mutex_lock(&amp;mutex); while(iCount &lt; 100) &#123; pthread_cond_wait(&amp;cond, &amp;mutex); &#125; printf(&quot;iCount &gt;= 100\\r\\n&quot;); iCount = 0; pthread_mutex_unlock(&amp;mutex);&#125; 那么条件变量解决的问题就是：有时候需要等待某个条件变量的出现才能进行下一步操作。如果使用忙等待，会浪费 CPU 资源，并且可能会导致程序出现死锁等问题。而使用条件变量可以使线程在等待条件变量时进入休眠状态，从而避免了忙等待和浪费 CPU 资源的问题。 为什么条件变量要结合锁来使用 先说结论-都是为了防止唤醒丢失问题 首先，解决共享变量判断与pthread_cond_wait调用的原子性。 条件变量的作用是在等待某个条件达成时自身要进行睡眠或阻塞，避免忙等待带来的不必要消耗，所以条件变量的作用在于同步。条件变量这个变量其实本身不包含条件信息，条件的判断不在pthread_cond_wait函数功能中，而需要外面进行条件判断。这个条件通常是多个线程或进程的共享变量，这样就很清楚了，对于共享变量很可能产生竞争条件尤其还对共享变量加了条件限制，所以从这个角度看，必须对共享变量加上互斥锁。 下图展示了没有互斥锁保护下的访问过程 123456789Process A Process Bpthread_mutex_lock(&amp;mutex);while (condition == FALSE) condition = TRUE; pthread_cond_signal(&amp;cond);pthread_cond_wait(&amp;cond, &amp;mutex); 其次，保证了线程在陷入wait后至被加入唤醒队列这段时间内是原子的。 pthread_cond_wait这个函数的过程我们必须了解，他的功能是阻塞自己等待其他程序通知其条件变量成立，因此在阻塞自己加入唤醒队列之后会释放锁，在条件变量的信号到来时，线程会被唤醒并重新尝试获取互斥锁mutex，以便继续执行。 试想一下，如果进程A调用了pthread_cond_wait，进入了唤醒队列，进行了解锁，这时候由于进程A时间片到期，轮换到进程B，进程B一直想要这把锁，现在终于拿到了，它干完了事情，调用pthread_cond_signal想唤醒A但是A并未完成睡眠等待条件达成，所以这个唤醒信号就丢失了。 参考 互斥锁、条件变量、读写锁、自旋锁、信号量 信号量与条件变量","categories":[{"name":"Linux","slug":"Linux","permalink":"https://leoschopen.github.io/categories/Linux/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://leoschopen.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","permalink":"https://leoschopen.github.io/tags/Linux/"},{"name":"进程同步","slug":"进程同步","permalink":"https://leoschopen.github.io/tags/%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://leoschopen.github.io/categories/Linux/"}]},{"title":"C++ 浅析static的若干注意事项与场景","slug":"析static的若干场景","date":"2023-05-18T14:04:00.000Z","updated":"2023-09-01T12:42:35.205Z","comments":true,"path":"2023/05/18/析static的若干场景/","link":"","permalink":"https://leoschopen.github.io/2023/05/18/%E6%9E%90static%E7%9A%84%E8%8B%A5%E5%B9%B2%E5%9C%BA%E6%99%AF/","excerpt":"","text":"内存 在C语言中，定义的静态变量在程序中的存储位置取决于它是否被初始化。如果静态变量被初始化了，它就会被分配到数据段（Data Segment）中；如果静态变量没有被初始化，它就会被分配到BSS段（Block Started by Symbol）中 1234567891011#include &lt;stdio.h&gt;int count = 0; // 初始化的全局变量static int array[100] = &#123;1, 2&#125;; // 初始化的静态变量int main() &#123; static int a; //BSS printf(&quot;count = %d\\n&quot;, count); printf(&quot;array[0] = %d\\n&quot;, array[0]); return 0;&#125; 静态局部变量 静态局部变量只会初始化一次，这也是“Meyers Singleton”的实现的依据。这种实现方式利用了C++11中静态局部变量的特性，可以保证在多线程环境下只有一个实例被创建，并且在程序运行期间一直存在。这种实现方式的优点是简单、线程安全，而且只有在需要使用单例对象的时候才会创建它，不会占用过多的内存空间。 注意，在C++11之前，静态局部变量的特性与C++11中的静态局部变量略有不同。具体来说，静态局部变量在C++11之前也只会被初始化一次，但是在多线程环境下并没有保证线程安全。为了解决这个问题，需要使用一些线程同步的机制，例如互斥锁（Mutex）、信号量（Semaphore）、原子操作等。另外，也可以使用其他的单例模式实现方式，例如双检锁（Double-Checked Locking）等。 123456789101112131415161718192021222324252627class Singleton&#123;private: Singleton()&#123; cout &lt;&lt; &quot;创建成功！&quot; &lt;&lt; endl; &#125;public: static Singleton &amp;getInstance()&#123; static Singleton instance; return instance; &#125;&#125;;void threadFunc()&#123; Singleton &amp;singleton = Singleton::getInstance();&#125;int main()&#123; //创建3个线程，每个线程都调用getInstance()函数 thread t1(threadFunc); thread t2(threadFunc); thread t3(threadFunc); t1.join(); t2.join(); t3.join(); return 0;&#125; 注意要链接pthread库 -lpthread 最终只会输出一个创建成功 类的静态成员 这个成员直接与类相关，和对象是没有关系的，但是对象可以访问共享，静态成员函数没有this指针，不能定义为const函数，因为我本来就和对象无关，const没有意义 存在于任何类的对象之外，在构建类的时候，会将静态成员定义在类的外面而不是类中，类的存储空间里不会有这一块内容 static关键字只在类内写，在类外不写，而且static函数中不要有非static成员，因为我掉你这个函数的时候，没有this指针，对象都不存在 类的静态成员不要再内部进行初始化，除了使用constexpr关键字，可以用字面值替换，但不是在内存中真的声明了一个地方，只是在这个类内进行一个数据的替换，如果想要在类外进行调用使用还是要进行一个类外的声明。 类的静态成员必须要类外初始化，c++11以后，只有在静态成员变量声明为 constexpr 或者枚举类型时，才能在类内进行初始化。对于其他类型的非常量静态成员变量，仍然需要在类外部进行初始化。 只有非静态成员变量才属于类的对象上，静态以及非静态成员函数都不属于类对象 C++ 中 static 对象的初始化 C++中的static对象是指存储区不属于stack和heap、”寿命”从被构造出来直至程序结束为止的对象。这些对象包括全局对象，定义于namespace作用域的对象，在class、function以及file作用域中被声明为static的对象。其中，函数内的static对象称为local static 对象，而其它static对象称为non-local static对象。 对于local static对象，在其所属的函数被调用之前，该对象并不存在，即只有在第一次调用对应函数时，local static对象才被构造出来。 而对于non-local static对象，在main()函数开始前就已经被构造出来，并在main()函数结束后被析构。 C++规定，non-local static 对象的初始化发生在 main 函数执行之前。但 C++没有规定多个 non-local static 对象的初始化顺序，尤其是来自多个编译单元的 non-local static 对象，他们的初始化顺序是随机的。 然而，对于 local static 对象，其初始化发生在控制流第一次执行到该对象的初始化语句时。 non-local static 对象的初始化发生在 main 函数之前的单线程启动阶段，所以无需担心线程安全问题。但是 local static 对象则不同，多个线程的控制流可能同时到达其初始化语句。 在 C++11 之前，在多线程环境下 local static 对象的初始化并不是线程安全的。具体表现就是：如果一个线程正在执行 local static 对象的初始化语句但还没有完成初始化，此时若其它线程也执行到该语句，那么这个线程会认为自己是第一次执行该语句并进入该 local static 对象的构造函数中。这会造成这个 local static 对象的重复构造，进而产生内存泄露问题。 在文章的后半部分会看到，local static 对象在单例模式中有着广泛的应用，为了解决 local static 对象在多线程环境下的重复构造问题，程序员想出了很多方法。而 C++11 则在语言的规范中解决了这个问题。C++11 规定，在一个线程开始 local static 对象的初始化后完成初始化前，其他线程执行到这个 local static 对象的初始化语句就会等待，直到该 local static 对象初始化完成。 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;using namespace std;class InnerClassA &#123; public: InnerClassA() &#123; cout &lt;&lt; &quot;in ctor of InnerClassA&quot; &lt;&lt; endl; &#125;&#125;;class InnerClassB &#123; public: InnerClassB() &#123; cout &lt;&lt; &quot;in ctor of InnerClassB&quot; &lt;&lt; endl; &#125; ~InnerClassB() &#123; cout &lt;&lt; &quot;in dtor of InnerClassB&quot; &lt;&lt; endl; &#125;&#125;;class WrapperClassA &#123; public: WrapperClassA() &#123;&#125; InnerClassA&amp; singleton() &#123; static InnerClassA innerObjA; // local static object return innerObjA; &#125;&#125;;// class with non-local static objectclass WrapperClassB &#123; public: WrapperClassB() &#123;&#125; static InnerClassB innerObjB;&#125;;InnerClassB WrapperClassB::innerObjB;int main(int argc, char* argv[]) &#123; cout &lt;&lt; &quot;main() started.&quot; &lt;&lt; endl; WrapperClassA objA; objA.singleton(); //只有去掉注释执行该语句时,innerObjA才被构造出来 cout &lt;&lt; &quot;main() terminated.&quot; &lt;&lt; endl; return 1;&#125; 单例设计模式的饿汉模式存在的no-local static问题 123456789101112class single &#123;private: static single* p; single() &#123;&#125; ~single() &#123;&#125;public: static single* getinstance();&#125;single* single::p = new single();single* single::getinstance() &#123; return p;&#125; static函数/变量定义到头文件中，而该头文件被不同的文件引用 参考：https://blog.csdn.net/qq_43121830/article/details/116711159 实际测试也可以看到，第一种情况下，static变量在不同文件中的地址不一样 使用两个文件引用相同头文件（只有static&amp;&amp;不加预编译指令） 使用两个文件引用相同头文件（有其他变量&amp;&amp;不加预编译指令） 使用两个文件引用相同头文件（有其他变量&amp;&amp;加预编译指令） 两种修正方法与相关知识点","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/tags/c/"}],"keywords":[]},{"title":"数组名作为函数参数的问题&sizeof()函数","slug":"数组名作为函数参数的问题","date":"2020-07-31T09:07:00.000Z","updated":"2020-07-31T09:12:15.123Z","comments":true,"path":"2020/07/31/数组名作为函数参数的问题/","link":"","permalink":"https://leoschopen.github.io/2020/07/31/%E6%95%B0%E7%BB%84%E5%90%8D%E4%BD%9C%E4%B8%BA%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"1234567891011121314151617181920#include&lt;bits/stdc++.h&gt;using namespace std;const int N = 8;static int array[N]=&#123;0&#125;;template&lt;class T&gt;int length(T array)//或者int length(int array[])&#123; cout&lt;&lt;&quot;sizeof(arr):&quot;&lt;&lt;sizeof(arr)&lt;&lt;endl; cout&lt;&lt;&quot;sizeof(arr[0]):&quot;&lt;&lt;sizeof(arr[0])&lt;&lt;endl; return sizeof(arr) / sizeof(arr[0]);&#125;int main()&#123; cout&lt;&lt;&amp;array&lt;&lt;endl; cout&lt;&lt;sizeof(&amp;array)&lt;&lt;endl; cout&lt;&lt;sizeof(array)&lt;&lt;endl; cout&lt;&lt;sizeof(array[0])&lt;&lt;endl; cout&lt;&lt;sizeof(array)/sizeof(array[0])&lt;&lt;endl; cout&lt;&lt;length(array)&lt;&lt;endl; return 0;&#125; 结果： 123456780x4a706083248sizeof(arr):8sizeof(arr[0]):42 出现直接计算和在传入参数然后在数组里面计算的方法结果不一样的原因： 1，arr 本身是左值（但不可仅凭此表达式修改），指代数组对象。不过 arr 会在大多数场合隐式转换成右值表达式 &amp;(arr[0]) 。为指针类型，指向 arr[0] 。&amp;arr 是右值表达式，为指针类型，指向 arr 本身。简单来说就是 arr 本身不是地址而是指代整个数组，只不过会隐式转成指针罢了。arr （转换后）和 &amp;arr 类型不同，数值相等是因为 arr 和 arr[0] 地址相同，这里地址指首地址。 也就是说，传入的只是首地址，不代表整个整个数组，应该修改为int length（T &amp;arr）这个时候传入的是数组首地址； 2，sizeof实际上是获取了数据在内存中所占用的存储空间，以字节为单位来计数。 在64位系统里，地址总线为64位，因此我们需要64个0和1来寻址，则指针需要8个字节，同理，32位需要4个字节，16位8086的指针需要2个字节。 此外，C/C++中，sizeof 是判断数据类型长度符的关键字，属于操作符，用于判断数据zhi类型或者表达式长度，不是一个函数，是编译的时候确定大小的。动态分配是运行过程中得到大小的，也就是说C++中new出来的内存，sizeof都无法统计的，退一步说，即使时new出来的空间也有可能失败，所以sizeof无法统计动态分配的内存大小。 123456//使用new关键字，在堆区开辟一个int数组int* arr = new int[5]&#123;1,2,3,4,5&#125;; //统计一个指针的大小，32位系统指针占4字节，64位系统指针占8字节cout &lt;&lt; sizeof(arr) &lt;&lt; endl;//解指针，32位系统下，结果和上面一样，因为arr指针指向的时数组的首元素，int类型占4字节cout &lt;&lt; sizeof(*arr) &lt;&lt; endl;","categories":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}],"tags":[{"name":"参数","slug":"参数","permalink":"https://leoschopen.github.io/tags/%E5%8F%82%E6%95%B0/"}],"keywords":[{"name":"c++","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}]},{"title":"快速幂与取模运算法则（二分法实现）","slug":"快速幂与取模运算法则（二分法实现）","date":"2020-07-30T02:44:00.000Z","updated":"2020-07-31T09:19:10.196Z","comments":true,"path":"2020/07/30/快速幂与取模运算法则（二分法实现）/","link":"","permalink":"https://leoschopen.github.io/2020/07/30/%E5%BF%AB%E9%80%9F%E5%B9%82%E4%B8%8E%E5%8F%96%E6%A8%A1%E8%BF%90%E7%AE%97%E6%B3%95%E5%88%99%EF%BC%88%E4%BA%8C%E5%88%86%E6%B3%95%E5%AE%9E%E7%8E%B0%EF%BC%89/","excerpt":"","text":"学习二分法的时候遇到了一个题目： 给定三个正整数，求a^b%m的值，纠结了好一会，最后发现问题出现在对取模运算法则的不熟悉上面 1234567long long normalPower(long long base,long long power)&#123; long long result=1; for(int i=1;i&lt;=power;i++)&#123; result=result*base; &#125; return result%m;&#125; 当b的值比较小的时候可以直接运算，但当较大(&gt;8)就会造成复杂度过大（O(N)）以及溢出的情况 下面寻求解决办法： 1，首先要熟悉取模运算法则 (a + b) % p = (a % p + b % p) % p （1） (a - b) % p = (a % p - b % p ) % p （2） (a * b) % p = (a % p * b % p) % p （3） 第三条可以得出：多个因子连续的乘积取模的结果等于每个因子取模后的乘积再取模的结果。也就是说， (a*b*c)%d=(a%d*b%d*c%d)%d; 有这个法则我们改进代码 1234567long long normalPower(long long base,long long power)&#123; long long result=1; for(int i=1;i&lt;=power;i++)&#123; result=result*base%m;//result=result*base;result=result%m; &#125; return result;&#125; 这个算法的时间复杂度为O(N),虽然很大程度上解决了溢出的问题，但当b大的时候还是比较慢 2，然后简化运算 我们发现 3^10^ =(3*3)^5^ 3^10^ =9^5^ *3^1^ 此时指数由10缩减一半变成了5，而底数变成了原来的平方，求3^10 原本需要执行10次循环操作，求9^5 却只需要执行5次循环操作，但是3^10 却等于9^5, 我们用一次（底数做平方操作）的操作减少了原本一半的循环量，特别是在幂特别大的时候效果非常好，例如2^10000^ =4^5000^,底数只是做了一个小小的平方操作，而指数就从10000变成了5000，减少了5000次的循环操作。 123456789101112131415long long normalPower(long long base,long long power)&#123; long long result=1; while(power&gt;0)&#123; if(power&amp;1)&#123; power-=1; result=result*base % m; power/=2; base=base*base % m; &#125;else&#123; power/=2; base=base*base % m; &#125; &#125; return result;&#125; 3,最后优化代码 我们发现代码有一些地方是重复出现的，我们做一些修改 123456789101112long long normalPower(long long base,long long power)&#123; long long result=1; while(power&gt;0)&#123; if(power&amp;1)&#123; power-=1; result=result*base % m; &#125; power/=2; base=base*base % m; &#125; return result;&#125; 在判断power为奇数时，我们采用power&amp;1的方式，而power/=2也可以换成power&gt;&gt;=1向右移位； 最后测试一下用时 2 1000000000000000000 3 1 the time cost is0.001 棒(๑•̀ㅂ•́)و","categories":[{"name":"algorithm","slug":"algorithm","permalink":"https://leoschopen.github.io/categories/algorithm/"}],"tags":[{"name":"二分法","slug":"二分法","permalink":"https://leoschopen.github.io/tags/%E4%BA%8C%E5%88%86%E6%B3%95/"}],"keywords":[{"name":"algorithm","slug":"algorithm","permalink":"https://leoschopen.github.io/categories/algorithm/"}]},{"title":"printf(\"%f\",3)输出为0,printf(\"%d\",3.1)输出一个大的数","slug":"222","date":"2020-07-21T01:33:00.000Z","updated":"2020-07-21T01:34:33.246Z","comments":true,"path":"2020/07/21/222/","link":"","permalink":"https://leoschopen.github.io/2020/07/21/222/","excerpt":"","text":"原因在于printf，printf不会关心你输入的参数的类型，你输入的实际是 printf(“%f”,3)，但是这个整型3不会被隐式类型转换为浮点型，而是被直接按内存内容当作浮点型 也就是说，内部使用等价于 int i = 3; printf(“%f”, *(float*)&amp;i) 不幸的是，整型3在内存布局上如果看成浮点数，它就是接近于0 这是不定参数的特点，没有类型检查，没有类型转换 在C语言标准中，浮点数是采用IEEE754标准 float类型数据存储格式如下： ​ 最高位最低位符号S 阶码E 尾数M 最高位 31 位 ,保存符号位 S“, 0”表示正数 ,“1”表示负数 30 位～23 位 ,共 8 位 ,移码方式(指数值加上偏移量127)保存指数部分 ,称为阶码 22 位～0 位 ,共 23 位 ,保存系数部分 ,称为尾数 ,对于规范化二进制数 ,整数位的前导“1”不保存 。 ​ 隐含 直接保存小数部分 对于 double 型 ,IEEE 754 - 1985标准规定用64 位表示 ,具体如下: ·最高位63 位 ,保存 S“, 0”正数“, 1”负数; ·62 位～52 位 ,共 11 位 ,移码方式(指数值加1023)保存指数 ,称为阶码; ​ ·51 位～0 位 ,共 52 位 ,保存系数部分 ,称为尾数 ,对于规范化二进制数 ,整数位的“1”不保存隐含) ,直接保存小数部分 将5.01压入栈，为double的数，栈8个字节。 ​ 而执行printf(“%d/n”, 5.01);则只需要取前四个字节就可以了。 取出来为. printf(“%f/n”, 5); 将5压入栈为 0000 0000 0000 0000 0000 0000 0000 0101，执行printf(“%f/n”, 5)；需要从栈中取8个字节， 取0000 0000 0000 0000 0000 0000 0000 0101之后，还要取他之后的四个字节， 但不管如何，前四个字节为0000 0000 0000 0000 0000 0000 0000 0101的浮点数为0.000000，所以输出0.000000 注意：内存内容是没有改变的，决定内存中内容的语义是读取的格式，float和double的存储格式和int类型的格式区别非常大。（但是都是低字节放在前面，高字节放在后面）","categories":[{"name":"c","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}],"tags":[{"name":"c","slug":"c","permalink":"https://leoschopen.github.io/tags/c/"}],"keywords":[{"name":"c","slug":"c","permalink":"https://leoschopen.github.io/categories/c/"}]},{"title":"关于对Exception in thread \"main\" java.lang.NullPointerException的报错","slug":"111","date":"2020-07-21T01:30:00.000Z","updated":"2020-08-18T14:15:18.003Z","comments":true,"path":"2020/07/21/111/","link":"","permalink":"https://leoschopen.github.io/2020/07/21/111/","excerpt":"","text":"① Exception in thread “main” java.lang.NullPointerException at CustomerList.addCustomer(CustomerList.java:21) at CustomerView.(CustomerView.java:13) at CustomerView.main(CustomerView.java:161) 1234567891011121314151617public class CustomerList &#123; private static Customer[] customers;//用来保存客户对象的数组 private static int total = 0;//记录已保存客户对象的数量 public CustomerList(int totalCustomer)&#123; customers = new Customer[totalCustomer]; //原因在这里，原来是Customer[] customers = new Customer[totalCustomer];报错 &#125; public boolean addCustomer(Customer customer)&#123; if(total&gt;=customers.length)&#123; return false; &#125; customers[total++] = customer; return true; &#125; &#125; 12345678910public class CustomerView &#123; private CustomerList customers = new CustomerList(10); //Customer[] customers = new Customer[10] public CustomerView() &#123; Customer cust = new Customer(&#x27;男&#x27;, &quot;张三&quot;, 30, &quot;010-56253825&quot;, &quot;abc@email.com&quot;); customers.addCustomer(cust); &#125; &#125; 错误的地方重新再方法内声明了customers，造成原本的私有成员customers数组没有被初始化，只分配了空间，因此该数组中的类对象都被初始化为null了，就出现了空指针。 ② 还有一种情况是在JAVA SWING中，因为当我们想往toolbar（JPanel）里面添加组件,这里是4个button时,虽然我们已经在前面声明了toolbar,但是我们并没有将toolbar new出来,也就是没给他创建堆内存,这时遍会报空指针异常;只要将this.toolBar = new JToolBar();加在用它的前面即可(即toolbar.add的前面); 总结 类的实例数组，需要初始化。 其他 java异常分运行时异常和编译时异常 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/* * 一、异常体系结构 * * java.lang.Throwable * |-----java.lang.Error:一般不编写针对性的代码进行处理。 * |-----java.lang.Exception:可以进行异常的处理 * |------编译时异常(checked) * |-----IOException * |-----FileNotFoundException * |-----ClassNotFoundException * |------运行时异常(unchecked,RuntimeException) * |-----NullPointerException * |-----ArrayIndexOutOfBoundsException * |-----ClassCastException * |-----NumberFormatException * |-----InputMismatchException * |-----ArithmeticException * * * * 面试题：常见的异常都有哪些？举例说明 */public class ExceptionTest &#123; //******************以下是编译时异常*************************** @Test public void test7()&#123;// File file = new File(&quot;hello.txt&quot;);// FileInputStream fis = new FileInputStream(file);// // int data = fis.read();// while(data != -1)&#123;// System.out.print((char)data);// data = fis.read();// &#125;// // fis.close(); &#125; //******************以下是运行时异常*************************** //ArithmeticException @Test public void test6()&#123; int a = 10; int b = 0; System.out.println(a / b); &#125; //InputMismatchException @Test public void test5()&#123; Scanner scanner = new Scanner(System.in); int score = scanner.nextInt(); System.out.println(score); scanner.close(); &#125; //NumberFormatException @Test public void test4()&#123; String str = &quot;123&quot;; str = &quot;abc&quot;; int num = Integer.parseInt(str); &#125; //ClassCastException @Test public void test3()&#123; Object obj = new Date(); String str = (String)obj; &#125; //IndexOutOfBoundsException @Test public void test2()&#123; //ArrayIndexOutOfBoundsException// int[] arr = new int[10];// System.out.println(arr[10]); //StringIndexOutOfBoundsException String str = &quot;abc&quot;; System.out.println(str.charAt(3)); &#125; //NullPointerException @Test public void test1()&#123; // int[] arr = null;// System.out.println(arr[3]); String str = &quot;abc&quot;; str = null; System.out.println(str.charAt(0)); &#125; &#125; 异常解决方案： try-catch-finally结构,一般对编译时异常进行处理，将其延后到运行时。 throws + 异常类型 第一种方式真正解决了异常而第二种在调用者使用时，仍然会将异常抛给调用者。","categories":[{"name":"Java","slug":"Java","permalink":"https://leoschopen.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://leoschopen.github.io/tags/Java/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://leoschopen.github.io/categories/Java/"}]},{"title":"for(;;)和while(true)的区别","slug":"for-和while-true-的区别","date":"2020-07-03T07:28:00.000Z","updated":"2023-05-18T12:54:03.186Z","comments":true,"path":"2020/07/03/for-和while-true-的区别/","link":"","permalink":"https://leoschopen.github.io/2020/07/03/for-%E5%92%8Cwhile-true-%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"for(;;) 比 while(true) 好 “死循环”有两种写法：for(;;)和while(true)，两者其实是存在一些区别的，可以从底层的编译上看，使用前者会占用更少的寄存器。 12345 编译前 编译后 while (1)； mov eax,1 test eax,eax je foo+23h jmp foo+18h 12 编译前 编译后 for (；；)； jmp foo+23h","categories":[{"name":"Java ","slug":"Java","permalink":"https://leoschopen.github.io/categories/Java/"},{"name":"Compiler","slug":"Java/Compiler","permalink":"https://leoschopen.github.io/categories/Java/Compiler/"},{"name":"Algorithm","slug":"Java/Compiler/Algorithm","permalink":"https://leoschopen.github.io/categories/Java/Compiler/Algorithm/"}],"tags":[{"name":"java","slug":"java","permalink":"https://leoschopen.github.io/tags/java/"}],"keywords":[{"name":"Java ","slug":"Java","permalink":"https://leoschopen.github.io/categories/Java/"},{"name":"Compiler","slug":"Java/Compiler","permalink":"https://leoschopen.github.io/categories/Java/Compiler/"},{"name":"Algorithm","slug":"Java/Compiler/Algorithm","permalink":"https://leoschopen.github.io/categories/Java/Compiler/Algorithm/"}]},{"title":"MySQL基础、锁、事务、分库分表、优化","slug":"MySQL基础、锁、事务、分库分表、优化","date":"2020-04-16T03:23:00.000Z","updated":"2022-03-16T01:39:23.122Z","comments":true,"path":"2020/04/16/MySQL基础、锁、事务、分库分表、优化/","link":"","permalink":"https://leoschopen.github.io/2020/04/16/MySQL%E5%9F%BA%E7%A1%80%E3%80%81%E9%94%81%E3%80%81%E4%BA%8B%E5%8A%A1%E3%80%81%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E3%80%81%E4%BC%98%E5%8C%96/","excerpt":"","text":"基础 1. 数据库的三范式是什么？ 第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。 第二范式：要求实体的属性完全依赖于主关键字。所谓完全 依赖是指不能存在仅依赖主关键字一部分的属性。 第三范式：任何非主属性不依赖于其它非主属性。 2. MySQL 支持哪些存储引擎? MySQL 支持多种存储引擎,比如 InnoDB,MyISAM,Memory,Archive 等等.在大多数的情况下,直接选择使用 InnoDB 引擎都是最合适的,InnoDB 也是 MySQL 的默认存储引擎。 MyISAM 和 InnoDB 的区别有哪些： InnoDB 支持事务，MyISAM 不支持 InnoDB 支持外键，而 MyISAM 不支持 InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。 Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高； InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。 MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。 3. 超键、候选键、主键、外键分别是什么？ 超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。 候选键：是最小超键，即没有冗余元素的超键。 主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。 外键：在一个表中存在的另一个表的主键称此表的外键。 4. SQL 约束有哪几种？ NOT NULL: 用于控制字段的内容一定不能为空（NULL）。 UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。 PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。 FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。 CHECK: 用于控制字段的值范围。 5. MySQL 中的 varchar 和 char 有什么区别？ char 是一个定长字段,假如申请了char(10)的空间,那么无论实际存储多少内容.该字段都占用 10 个字符,而 varchar 是变长的,也就是说申请的只是最大长度,占用的空间为实际字符长度+1,最后一个字符存储使用了多长的空间. 在检索效率上来讲,char &gt; varchar,因此在使用中,如果确定某个字段的值的长度,可以使用 char,否则应该尽量使用 varchar.例如存储用户 MD5 加密后的密码,则应该使用 char。 6. MySQL中 in 和 exists 区别 MySQL中的in语句是把外表和内表作hash 连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。 如果查询的两个表大小相当，那么用in和exists差别不大。 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in。 not in 和not exists：如果查询语句使用了not in，那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论那个表大，用not exists都比not in要快。 7. drop、delete与truncate的区别 三者都表示删除，但是三者有一些差别： 8. 什么是存储过程？有哪些优缺点？ 存储过程是一些预编译的 SQL 语句。 1、更加直白的理解：存储过程可以说是一个记录集，它是由一些 T-SQL 语句组成的代码块，这些 T-SQL 语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。 2、存储过程是一个预编译的代码块，执行效率比较高,一个存储过程替代大量 T_SQL 语句 ，可以降低网络通信量，提高通信速率,可以一定程度上确保数据安全 但是,在互联网项目中,其实是不太推荐存储过程的,比较出名的就是阿里的《Java 开发手册》中禁止使用存储过程,我个人的理解是,在互联网项目中,迭代太快,项目的生命周期也比较短,人员流动相比于传统的项目也更加频繁,在这样的情况下,存储过程的管理确实是没有那么方便,同时,复用性也没有写在服务层那么好。 9. MySQL 执行查询的过程 客户端通过 TCP 连接发送连接请求到 MySQL 连接器，连接器会对该请求进行权限验证及连接资源分配 查缓存。（当判断缓存是否命中时，MySQL 不会进行解析查询语句，而是直接使用 SQL 语句和客户端发送过来的其他原始信息。所以，任何字符上的不同，例如空格、注解等都会导致缓存的不命中。） 语法分析（SQL 语法是否写错了）。 如何把语句给到预处理器，检查数据表和数据列是否存在，解析别名看是否存在歧义。 优化。是否使用索引，生成执行计划。 交给执行器，将数据保存到结果集中，同时会逐步将数据缓存到查询缓存中，最终将结果集返回给客户端。 更新语句执行会复杂一点。需要检查表是否有排它锁，写 binlog，刷盘，是否执行 commit。 事务 1. 什么是数据库事务？ 事务是一个不可分割的数据库操作序列，也是数据库并发控制的基本单位，其执行的结果必须使数据库从一种一致性状态变到另一种一致性状态。事务是逻辑上的一组操作，要么都执行，要么都不执行。 事务最经典也经常被拿出来说例子就是转账了。 假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。 2. 介绍一下事务具有的四个特征 事务就是一组原子性的操作，这些操作要么全部发生，要么全部不发生。事务把数据库从一种一致性状态转换成另一种一致性状态。 原子性。事务是数据库的逻辑工作单位，事务中包含的各操作要么都做，要么都不做 一致性。事 务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。因此当数据库只包含成功事务提交的结果时，就说数据库处于一致性状态。如果数据库系统 运行中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一部分已写入物理数据库，这时数据库就处于一种不正确的状态，或者说是 不一致的状态。 隔离性。一个事务的执行不能其它事务干扰。即一个事务内部的//操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务之间不能互相干扰。 持续性。也称永久性，指一个事务一旦提交，它对数据库中的数据的改变就应该是永久性的。接下来的其它操作或故障不应该对其执行结果有任何影响。 3. 说一下MySQL 的四种隔离级别 Read Uncommitted（读取未提交内容） 在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。 Read Committed（读取提交内容） 这是大多数数据库系统的默认隔离级别（但不是 MySQL 默认的）。它满足了隔离的简单定义：一个事务只能看见已经提交事务所做的改变。这种隔离级别 也支持所谓 的 不可重复读（Nonrepeatable Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一 select 可能返回不同结果。 Repeatable Read（可重读） 这是 MySQL 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。 Serializable（可串行化） 通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争。 MySQL 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别 事务隔离机制的实现基于锁机制和并发调度。其中并发调度使用的是MVVC（多版本并发控制），通过保存修改的旧版本信息来支持并发一致性读和回滚等特性。 因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是READ-COMMITTED(读取提交内容):，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）**并不会有任何性能损失。 InnoDB 存储引擎在 分布式事务 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别。 4. 什么是脏读？幻读？不可重复读？ 1、脏读：事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据 2、不可重复读：事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果 不一致。 3、幻读：系统管理员 A 将数据库中所有学生的成绩从具体分数改为 ABCDE 等级，但是系统管理员 B 就在这个时候插入了一条具体分数的记录，当系统管理员 A 改结束后发现还有一条记录没有改过来，就好像发生了幻觉一样，这就叫幻读。 不可重复读侧重于修改，幻读侧重于新增或删除（多了或少量行），脏读是一个事务回滚影响另外一个事务。 5. 事务的实现原理 事务是基于重做日志文件(redo log)和回滚日志(undo log)实现的。 每提交一个事务必须先将该事务的所有日志写入到重做日志文件进行持久化，数据库就可以通过重做日志来保证事务的原子性和持久性。 每当有修改事务时，还会产生 undo log，如果需要回滚，则根据 undo log 的反向语句进行逻辑操作，比如 insert 一条记录就 delete 一条记录。undo log 主要实现数据库的一致性。 6. MySQL事务日志介绍下？ innodb 事务日志包括 redo log 和 undo log。 undo log 指事务开始之前，在操作任何数据之前，首先将需操作的数据备份到一个地方。redo log 指事务中操作的任何数据，将最新的数据备份到一个地方。 事务日志的目的：实例或者介质失败，事务日志文件就能派上用场。 redo log redo log 不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入 redo 中。具体的落盘策略可以进行配置 。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 MySQL 服务的时候，根据 redo log 进行重做，从而达到事务的未入磁盘数据进行持久化这一特性。RedoLog 是为了实现事务的持久性而出现的产物。 undo log undo log 用来回滚行记录到某个版本。事务未提交之前，Undo 保存了未提交之前的版本数据，Undo 中的数据可作为数据旧版本快照供其他并发事务进行快照读。是为了实现事务的原子性而出现的产物,在 MySQL innodb 存储引擎中用来实现多版本并发控制。 7. 什么是MySQL的 binlog？ MySQL的 binlog 是记录所有数据库表结构变更（例如 CREATE、ALTER TABLE）以及表数据修改（INSERT、UPDATE、DELETE）的二进制日志。binlog 不会记录 SELECT 和 SHOW 这类操作，因为这类操作对数据本身并没有修改，但你可以通过查询通用日志来查看 MySQL 执行过的所有语句。 MySQL binlog 以事件形式记录，还包含语句所执行的消耗的时间，MySQL 的二进制日志是事务安全型的。binlog 的主要目的是复制和恢复。 binlog 有三种格式，各有优缺点： statement： 基于 SQL 语句的模式，某些语句和函数如 UUID, LOAD DATA INFILE 等在复制过程可能导致数据不一致甚至出错。 row： 基于行的模式，记录的是行的变化，很安全。但是 binlog 会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。 mixed： 混合模式，根据语句来选用是 statement 还是 row 模式。 8. 在事务中可以混合使用存储引擎吗？ 尽量不要在同一个事务中使用多种存储引擎，MySQL服务器层不管理事务，事务是由下层的存储引擎实现的。 如果在事务中混合使用了事务型和非事务型的表（例如InnoDB和MyISAM表）,在正常提交的情况下不会有什么问题。 但如果该事务需要回滚，非事务型的表上的变更就无法撤销，这会导致数据库处于不一致的状态，这种情况很难修复，事务的最终结果将无法确定。所以，为每张表选择合适的存储引擎非常重要。 9. MySQL中是如何实现事务隔离的? 读未提交和串行化基本上是不需要考虑的隔离级别，前者不加锁限制，后者相当于单线程执行，效率太差。 MySQL 在可重复读级别解决了幻读问题，是通过行锁和间隙锁的组合 Next-Key 锁实现的。 详细原理看这篇文章：https://haicoder.net/note/MySQL-interview/MySQL-interview-MySQL-trans-level.html 10. 什么是 MVCC？ MVCC， 即多版本并发控制。MVCC 的实现，是通过保存数据在某个时间点的快照来实现的。根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的。 11. MVCC 的实现原理 对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列： ROW ID：隐藏的自增 ID，如果表没有主键，InnoDB 会自动按 ROW ID 产生一个聚集索引树。 事务 ID：记录最后一次修改该记录的事务 ID。 回滚指针：指向这条记录的上一个版本。 我们拿上面的例子，对应解释下 MVCC 的实现原理，如下图： 如图，首先 insert 语句向表 t1 中插入了一条数据，a 字段为 1，b 字段为 1， ROW ID 也为 1 ，事务 ID 假设为 1，回滚指针假设为 null。当执行 update t1 set b=666 where a=1 时，大致步骤如下： 数据库会先对满足 a=1 的行加排他锁； 然后将原记录复制到 undo 表空间中； 修改 b 字段的值为 666，修改事务 ID 为 2； 并通过隐藏的回滚指针指向 undo log 中的历史记录； 事务提交，释放前面对满足 a=1 的行所加的排他锁。 在前面实验的第 6 步中，session2 查询的结果是 session1 修改之前的记录，这个记录就是来自 undolog 中。 因此可以总结出 MVCC 实现的原理大致是： InnoDB 每一行数据都有一个隐藏的回滚指针，用于指向该行修改前的最后一个历史版本，这个历史版本存放在 undo log 中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。其它事务此时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。 MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。 锁 1. 为什么要加锁? 当多个用户并发地存取数据时，在数据库中就会产生多个事务同时存取同一数据的情况。若对并发操作不加控制就可能会读取和存储不正确的数据，破坏数据库的一致性。 保证多用户环境下保证数据库完整性和一致性。 2. 按照锁的粒度分数据库锁有哪些？ 在关系型数据库中，可以按照锁的粒度把数据库锁分为行级锁(INNODB引擎)、表级锁(MYISAM引擎)和页级锁(BDB引擎 )。 行级锁 行级锁是MySQL中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。 开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。 开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。 页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。BDB支持页级锁 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般 MyISAM和InnoDB存储引擎使用的锁： MyISAM采用表级锁(table-level locking)。 InnoDB支持行级锁(row-level locking)和表级锁，默认为行级锁 3. 从锁的类别上分MySQL都有哪些锁呢？ 从锁的类别上来讲，有共享锁和排他锁。 共享锁: 又叫做读锁。 当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。 排他锁: 又叫做写锁。 当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。 用上面的例子来说就是用户的行为有两种，一种是来看房，多个用户一起看房是可以接受的。 一种是真正的入住一晚，在这期间，无论是想入住的还是想看房的都不可以。 锁的粒度取决于具体的存储引擎，InnoDB实现了行级锁，页级锁，表级锁。 他们的加锁开销从大到小，并发能力也是从大到小。 4. 数据库的乐观锁和悲观锁是什么？怎么实现的？ 数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。乐观并发控制（乐观锁）和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。在查询完数据的时候就把事务锁起来，直到提交事务。实现方式：使用数据库中的锁机制 乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。在修改数据的时候把事务锁起来，通过version的方式来进行锁定。实现方式：乐一般会使用版本号机制或CAS算法实现。 两种锁的使用场景 从上面对两种锁的介绍，我们知道两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下（多读场景），即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。 但如果是多写的情况，一般会经常产生冲突，这就会导致上层应用会不断的进行retry，这样反倒是降低了性能，所以一般多写的场景下用悲观锁就比较合适。 5. InnoDB引擎的行锁是怎么实现的？ InnoDB是基于索引来完成行锁 例: select * from tab_with_index where id = 1 for update; for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起 6. 什么是死锁？怎么解决？ 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。 常见的解决死锁的方法 1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。 2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率； 3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率； 如果业务处理不好可以用分布式事务锁或者使用乐观锁 7. 隔离级别与锁的关系 在Read Uncommitted级别下，读取数据不需要加共享锁，这样就不会跟被修改的数据上的排他锁冲突 在Read Committed级别下，读操作需要加共享锁，但是在语句执行完以后释放共享锁； 在Repeatable Read级别下，读操作需要加共享锁，但是在事务提交之前并不释放共享锁，也就是必须等待事务执行完毕以后才释放共享锁。 SERIALIZABLE 是限制性最强的隔离级别，因为该级别锁定整个范围的键，并一直持有锁，直到事务完成。 8. 优化锁方面的意见？ 使用较低的隔离级别 设计索引，尽量使用索引去访问数据，加锁更加精确，从而减少锁冲突 选择合理的事务大小，给记录显示加锁时，最好一次性请求足够级别的锁。列如，修改数据的话，最好申请排他锁，而不是先申请共享锁，修改时在申请排他锁，这样会导致死锁 不同的程序访问一组表的时候，应尽量约定一个相同的顺序访问各表，对于一个表而言，尽可能的固定顺序的获取表中的行。这样大大的减少死锁的机会。 尽量使用相等条件访问数据，这样可以避免间隙锁对并发插入的影响 不要申请超过实际需要的锁级别 数据查询的时候不是必要，不要使用加锁。MySQL的MVCC可以实现事务中的查询不用加锁，优化事务性能：MVCC只在committed read（读提交）和 repeatable read （可重复读）两种隔离级别 对于特定的事务，可以使用表锁来提高处理速度活着减少死锁的可能。 分库分表 1. 为什么要分库分表？ 分表 比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，会极大影响你的 sql执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。 分表就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。 分库 分库就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。 这就是所谓的分库分表。 2. 用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？ 这个其实就是看看你了解哪些分库分表的中间件，各个中间件的优缺点是啥？然后你用过哪些分库分表的中间件。 比较常见的包括： cobar TDDL atlas sharding-jdbc mycat cobar 阿里 b2b 团队开发和开源的，属于 proxy 层方案。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库 join 和分页等操作。 TDDL 淘宝团队开发的，属于 client 层方案。支持基本的 crud 语法和读写分离，但不支持 join、多表查询等语法。目前使用的也不多，因为还依赖淘宝的 diamond 配置管理系统。 atlas 360 开源的，属于 proxy 层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在 5 年前了。所以，现在用的公司基本也很少了。 sharding-jdbc 当当开源的，属于 client 层方案。确实之前用的还比较多一些，因为 SQL 语法支持也比较多，没有太多限制，而且目前推出到了 2.0 版本，支持分库分表、读写分离、分布式 id 生成、柔性事务（最大努力送达型事务、TCC 事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从 2017 年一直到现在，是有不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也可以选择的方案。 mycat 基于 cobar 改造的，属于 proxy 层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。但是确实相比于 sharding jdbc 来说，年轻一些，经历的锤炼少一些。 3. 如何对数据库如何进行垂直拆分或水平拆分的？ 水平拆分的意思，就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 垂直拆分的意思，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 两种分库分表的方式： 一种是按照 range 来分，就是每个库一段连续的数据，这个一般是按比如时间范围来的，但是这种一般较少用，因为很容易产生热点问题，大量的流量都打在最新的数据上了。 或者是按照某个字段hash一下均匀分散，这个较为常用。 range 来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。 hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表 读写分离、主从同步（复制） 1. 什么是MySQL主从同步？ 主从同步使得数据可以从一个数据库服务器复制到其他服务器上，在复制数据时，一个服务器充当主服务器（master），其余的服务器充当从服务器（slave）。 因为复制是异步进行的，所以从服务器不需要一直连接着主服务器，从服务器甚至可以通过拨号断断续续地连接主服务器。通过配置文件，可以指定复制所有的数据库，某个数据库，甚至是某个数据库上的某个表。 2. MySQL主从同步的目的？为什么要做主从同步？ 通过增加从服务器来提高数据库的性能，在主服务器上执行写入和更新，在从服务器上向外提供读功能，可以动态地调整从服务器的数量，从而调整整个数据库的性能。 提高数据安全-因为数据已复制到从服务器，从服务器可以终止复制进程，所以，可以在从服务器上备份而不破坏主服务器相应数据 在主服务器上生成实时数据，而在从服务器上分析这些数据，从而提高主服务器的性能 数据备份。一般我们都会做数据备份，可能是写定时任务，一些特殊行业可能还需要手动备份，有些行业要求备份和原数据不能在同一个地方，所以主从就能很好的解决这个问题，不仅备份及时，而且还可以多地备份，保证数据的安全 3. 如何实现MySQL的读写分离？ 其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。 4. MySQL主从复制流程和原理？ 基本原理流程，是3个线程以及之间的关联 主：binlog线程——记录下所有改变了数据库数据的语句，放进master上的binlog中； 从：io线程——在使用start slave 之后，负责从master上拉取 binlog 内容，放进自己的relay log中； 从：sql执行线程——执行relay log中的语句； 复制过程如下： Binary log：主数据库的二进制日志 Relay log：从服务器的中继日志 第一步：master在每个事务更新数据完成之前，将该操作记录串行地写入到binlog文件中。 第二步：salve开启一个I/O Thread，该线程在master打开一个普通连接，主要工作是binlog dump process。如果读取的进度已经跟上了master，就进入睡眠状态并等待master产生新的事件。I/O线程最终的目的是将这些事件写入到中继日志中。 第三步：SQL Thread会读取中继日志，并顺序执行该日志中的SQL事件，从而与主数据库中的数据保持一致。 5. MySQL主从同步延时问题如何解决？ MySQL 实际上在有两个同步机制，一个是半同步复制，用来 解决主库数据丢失问题；一个是并行复制，用来 解决主从同步延时问题。 半同步复制，也叫 semi-sync 复制，指的就是主库写入 binlog 日志之后，就会将强制此时立即将数据同步到从库，从库将日志写入自己本地的 relay log 之后，接着会返回一个 ack 给主库，主库接收到至少一个从库的 ack 之后才会认为写操作完成了。 并行复制，指的是从库开启多个线程，并行读取 relay log 中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。 MySQL优化 1. 如何定位及优化SQL语句的性能问题？ 对于低性能的SQL语句的定位，最重要也是最有效的方法就是使用执行计划，MySQL提供了explain命令来查看语句的执行计划。 我们知道，不管是哪种数据库，或者是哪种数据库引擎，在对一条SQL语句进行执行的过程中都会做很多相关的优化，对于查询语句，最重要的优化方式就是使用索引。 而执行计划，就是显示数据库引擎对于SQL语句的执行的详细情况，其中包含了是否使用索引，使用什么索引，使用的索引的相关信息等。 2. 大表数据查询，怎么优化 优化shema、sql语句+索引； 第二加缓存，memcached, redis； 主从复制，读写分离； 垂直拆分，根据你模块的耦合度，将一个大的系统分为多个小的系统，也就是分布式系统； 水平切分，针对数据量大的表，这一步最麻烦，最能考验技术水平，要选择一个合理的sharding key, 为了有好的查询效率，表结构也要改动，做一定的冗余，应用也要改，sql中尽量带sharding key，将数据定位到限定的表上去查，而不是扫描全部的表； 3. 超大分页怎么处理? 数据库层面,这也是我们主要集中关注的(虽然收效没那么大),类似于select * from table where age &gt; 20 limit 1000000,10 这种查询其实也是有可以优化的余地的. 这条语句需要 load1000000 数据然后基本上全部丢弃,只取 10 条当然比较慢. 当时我们可以修改为select * from table where id in (select id from table where age &gt; 20 limit 1000000,10).这样虽然也 load 了一百万的数据,但是由于索引覆盖,要查询的所有字段都在索引中,所以速度会很快。 解决超大分页,其实主要是靠缓存,可预测性的提前查到内容,缓存至redis等k-V数据库中,直接返回即可. 在阿里巴巴《Java开发手册》中,对超大分页的解决办法是类似于上面提到的第一种. 【推荐】利用延迟关联或者子查询优化超多分页场景。 说明：MySQL并不是跳过offset行，而是取offset+N行，然后返回放弃前offset行，返回N行，那当offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行SQL改写。 正例：先快速定位需要获取的id段，然后再关联： SELECT a.* FROM 表1 a, (select id from 表1 where 条件 LIMIT 100000,20 ) b where a.id=b.id 4. 统计过慢查询吗？对慢查询都怎么优化过？ 在业务系统中，除了使用主键进行的查询，其他的我都会在测试库上测试其耗时，慢查询的统计主要由运维在做，会定期将业务中的慢查询反馈给我们。 慢查询的优化首先要搞明白慢的原因是什么？ 是查询条件没有命中索引？是load了不需要的数据列？还是数据量太大？ 所以优化也是针对这三个方向来的， 首先分析语句，看看是否load了额外的数据，可能是查询了多余的行并且抛弃掉了，可能是加载了许多结果中并不需要的列，对语句进行分析以及重写。 分析语句的执行计划，然后获得其使用索引的情况，之后修改语句或者修改索引，使得语句可以尽可能的命中索引。 如果对语句的优化已经无法进行，可以考虑表中的数据量是否太大，如果是的话可以进行横向或者纵向的分表。 5. 如何优化查询过程中的数据访问 访问数据太多导致查询性能下降 确定应用程序是否在检索大量超过需要的数据，可能是太多行或列 确认MySQL服务器是否在分析大量不必要的数据行 查询不需要的数据。解决办法：使用limit解决 多表关联返回全部列。解决办法：指定列名 总是返回全部列。解决办法：避免使用SELECT * 重复查询相同的数据。解决办法：可以缓存数据，下次直接读取缓存 是否在扫描额外的记录。解决办法： 使用explain进行分析，如果发现查询需要扫描大量的数据，但只返回少数的行，可以通过如下技巧去优化： 使用索引覆盖扫描，把所有的列都放到索引中，这样存储引擎不需要回表获取对应行就可以返回结果。 改变数据库和表的结构，修改数据表范式 重写SQL语句，让优化器可以以更优的方式执行查询。 6. 如何优化关联查询 确定ON或者USING子句中是否有索引。 确保GROUP BY和ORDER BY只有一个表中的列，这样MySQL才有可能使用索引。 7. 数据库结构优化 一个好的数据库设计方案对于数据库的性能往往会起到事半功倍的效果。 需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。 将字段很多的表分解成多个表 对于字段较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。 因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 增加中间表 对于需要经常联合查询的表，可以建立中间表以提高查询效率。 通过建立中间表，将需要通过联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询。 增加冗余字段 设计数据表时应尽量遵循范式理论的规约，尽可能的减少冗余字段，让数据库设计看起来精致、优雅。但是，合理的加入冗余字段可以提高查询速度。 表的规范化程度越高，表和表之间的关系越多，需要连接查询的情况也就越多，性能也就越差。 注意： 冗余字段的值在一个表中修改了，就要想办法在其他表中更新，否则就会导致数据不一致的问题。 8. MySQL数据库cpu飙升到500%的话他怎么处理？ 当 cpu 飙升到 500%时，先用操作系统命令 top 命令观察是不是 MySQLd 占用导致的，如果不是，找出占用高的进程，并进行相关处理。 如果是 MySQLd 造成的， show processlist，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确， index 是否缺失，或者实在是数据量太大造成。 一般来说，肯定要 kill 掉这些线程(同时观察 cpu 使用率是否下降)，等进行相应的调整(比如说加索引、改 sql、改内存参数)之后，再重新跑这些 SQL。 也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。 9. 大表怎么优化？ 类似的问题：某个表有近千万数据，CRUD比较慢，如何优化？分库分表了是怎么做的？分表分库了有什么问题？有用到中间件么？他们的原理知道么？ 当MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下： 限定数据的范围： 务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内； 读/写分离： 经典的数据库拆分方案，主库负责写，从库负责读； 缓存： 使用MySQL的缓存，另外对重量级、更新少的数据可以考虑； 通过分库分表的方式进行优化，主要有垂直分表和水平分表。 参考 MySQL https://blog.csdn.net/ThinkWon/article/details/104778621 https://haicoder.net/note/mysql-interview/mysql-interview-mysql-binlog.html https://www.modb.pro/db/40241 https://www.jianshu.com/p/05da0fc0950e https://blog.csdn.net/ThinkWon/article/details/104778621","categories":[{"name":"数据库","slug":"数据库","permalink":"https://leoschopen.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://leoschopen.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"keywords":[{"name":"数据库","slug":"数据库","permalink":"https://leoschopen.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]}]}